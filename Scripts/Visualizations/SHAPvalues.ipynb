{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "# load the model and tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"NikolajMunch/test\", use_fast=True)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"NikolajMunch/test\").cuda()\n",
    "\n",
    "# build a pipeline object to do predictions\n",
    "pred = transformers.pipeline(\"text-classification\", model=model, device=0, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "df = pd.read_csv(\"copd_heart_failure_df_no2.csv\")\n",
    "\n",
    "#Select only columns reason_clean, label_list\n",
    "df = df[['reason_clean', 'disease_label']]\n",
    "\n",
    "#Split into train and test\n",
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "train_df.columns = [\"text\", \"labels\"]\n",
    "test_df.columns = [\"text\", \"labels\"]\n",
    "\n",
    "explainer = shap.Explainer(pred, masker=shap.maskers.Text(collapse_mask_token=True))\n",
    "\n",
    "test_df2 = test_df[test_df['text'].apply(lambda x: len(x.split()) > 3)] #Ensure enough words for token masking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(test_df2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save shap-values for all pre-exam texts in test df\n",
    "with open('shap_values.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot most important words towards label 1 /hf\n",
    "shap.plots.bar(shap_values[:,:,\"LABEL_1\"].mean(0), order=shap.Explanation.argsort.flip, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for label 0 /copd\n",
    "shap.plots.bar(shap_values[:,:,\"LABEL_1\"].mean(0), order=shap.Explanation.argsort.flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot individual sentences, this is done for a few example sentences as shown in the paper Figure 4\n",
    "shap_values_sent = explainer(\"Insert example sentence here\")\n",
    "\n",
    "shap.plots.text(shap_values_sent)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
